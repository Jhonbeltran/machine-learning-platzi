{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  Según distintos benchmarks (papers, kaggle.com) los **algoritmos de uso general** que tienen más veces la mejor performance son: **Gradient Boosted Trees, Random Forest y SVM**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/benchmark_algs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>duration.1</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>opening_gross</th>\n",
       "      <th>screens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>425000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4834.0</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>77025481.0</td>\n",
       "      <td>3452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>169.0</td>\n",
       "      <td>48350.0</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>139802190.0</td>\n",
       "      <td>4362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>148.0</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>70403148.0</td>\n",
       "      <td>3929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164.0</td>\n",
       "      <td>106759.0</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>160887295.0</td>\n",
       "      <td>4404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275000000.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>150.0</td>\n",
       "      <td>45757.0</td>\n",
       "      <td>215000000.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>29210849.0</td>\n",
       "      <td>3904.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   production_budget  title_year  aspect_ratio  duration.1  \\\n",
       "0        425000000.0      2009.0          1.78       178.0   \n",
       "1        300000000.0      2007.0          2.35       169.0   \n",
       "2        300000000.0      2015.0          2.35       148.0   \n",
       "3        275000000.0      2012.0          2.35       164.0   \n",
       "4        275000000.0      2013.0          2.35       150.0   \n",
       "\n",
       "   cast_total_facebook_likes       budget  imdb_score  opening_gross  screens  \n",
       "0                     4834.0  237000000.0         7.9     77025481.0   3452.0  \n",
       "1                    48350.0  300000000.0         7.1    139802190.0   4362.0  \n",
       "2                    11700.0  245000000.0         6.8     70403148.0   3929.0  \n",
       "3                   106759.0  250000000.0         8.5    160887295.0   4404.0  \n",
       "4                    45757.0  215000000.0         6.5     29210849.0   3904.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_csv('intermediate_results/X.csv')\n",
    "y = X['worldwide_gross']\n",
    "X = X.drop('worldwide_gross',axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "treedot = export_graphviz(model,\n",
    "                         out_file=None,\n",
    "                         feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'digraph Tree {\\nnode [shape=box] ;\\n0 [label=\"opening_gross <= 41613376.0\\\\nmse = 4.491994363696598e+16\\\\nsamples = 1665\\\\nvalue = 141540319.054\"] ;\\n1 [label=\"opening_gross <= 22074048.0\\\\nmse = 1.3333822193127812e+16\\\\nsamples = 1506\\\\nvalue = 92999937.199\"] ;\\n0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\\n2 [label=\"mse = 4923666241203546.0\\\\nsamples = 1257\\\\nvalue = 64781848.271\"] ;\\n1 -> 2 ;\\n3 [label=\"mse = 3.147813101998756e+16\\\\nsamples = 249\\\\nvalue = 235450289.735\"] ;\\n1 -> 3 ;\\n4 [label=\"opening_gross <= 70351576.0\\\\nmse = 1.1039811871593606e+17\\\\nsamples = 159\\\\nvalue = 601300162.289\"] ;\\n0 -> 4 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\\n5 [label=\"mse = 4.067538845924509e+16\\\\nsamples = 92\\\\nvalue = 440868287.554\"] ;\\n4 -> 5 ;\\n6 [label=\"mse = 1.2226485798747622e+17\\\\nsamples = 67\\\\nvalue = 821594676.851\"] ;\\n4 -> 6 ;\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treedot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"828pt\" height=\"269pt\"\n",
       " viewBox=\"0.00 0.00 828.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-265 824,-265 824,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"492.5,-261 298.5,-261 298.5,-193 492.5,-193 492.5,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"395.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">opening_gross &lt;= 41613376.0</text>\n",
       "<text text-anchor=\"middle\" x=\"395.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4.491994363696598e+16</text>\n",
       "<text text-anchor=\"middle\" x=\"395.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1665</text>\n",
       "<text text-anchor=\"middle\" x=\"395.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 141540319.054</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"387,-157 186,-157 186,-89 387,-89 387,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">opening_gross &lt;= 22074048.0</text>\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 1.3333822193127812e+16</text>\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1506</text>\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 92999937.199</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M359.8093,-192.9465C350.2109,-183.7884 339.7253,-173.7838 329.7634,-164.2788\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.9221,-161.5009 322.2709,-157.13 327.0898,-166.5655 331.9221,-161.5009\"/>\n",
       "<text text-anchor=\"middle\" x=\"322.8576\" y=\"-178.4231\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"606,-157 405,-157 405,-89 606,-89 606,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"505.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">opening_gross &lt;= 70351576.0</text>\n",
       "<text text-anchor=\"middle\" x=\"505.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 1.1039811871593606e+17</text>\n",
       "<text text-anchor=\"middle\" x=\"505.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 159</text>\n",
       "<text text-anchor=\"middle\" x=\"505.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 601300162.289</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M431.5181,-192.9465C441.2046,-183.7884 451.7864,-173.7838 461.8397,-164.2788\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"464.539,-166.5434 469.401,-157.13 459.7299,-161.4569 464.539,-166.5434\"/>\n",
       "<text text-anchor=\"middle\" x=\"468.7003\" y=\"-178.4202\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"173,-53 0,-53 0,0 173,0 173,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4923666241203546.0</text>\n",
       "<text text-anchor=\"middle\" x=\"86.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1257</text>\n",
       "<text text-anchor=\"middle\" x=\"86.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 64781848.271</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.9875,-88.9777C194.7288,-78.7204 171.5176,-67.521 150.6933,-57.4732\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.1466,-54.2884 141.6192,-53.095 149.1047,-60.5929 152.1466,-54.2884\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"385.5,-53 191.5,-53 191.5,0 385.5,0 385.5,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 3.147813101998756e+16</text>\n",
       "<text text-anchor=\"middle\" x=\"288.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 249</text>\n",
       "<text text-anchor=\"middle\" x=\"288.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 235450289.735</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M287.2051,-88.9777C287.3759,-80.7364 287.5593,-71.887 287.7328,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"291.2376,-63.3189 287.9456,-53.2485 284.2391,-63.1738 291.2376,-63.3189\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"600.5,-53 406.5,-53 406.5,0 600.5,0 600.5,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"503.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 4.067538845924509e+16</text>\n",
       "<text text-anchor=\"middle\" x=\"503.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 92</text>\n",
       "<text text-anchor=\"middle\" x=\"503.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 440868287.554</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M504.7949,-88.9777C504.6241,-80.7364 504.4407,-71.887 504.2672,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"507.7609,-63.1738 504.0544,-53.2485 500.7624,-63.3189 507.7609,-63.1738\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"820,-53 619,-53 619,0 820,0 820,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"719.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mse = 1.2226485798747622e+17</text>\n",
       "<text text-anchor=\"middle\" x=\"719.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 67</text>\n",
       "<text text-anchor=\"middle\" x=\"719.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 821594676.851</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M580.9484,-88.9777C603.7971,-78.6744 628.7539,-67.4205 651.1128,-57.3381\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"652.8452,-60.3964 660.5224,-53.095 649.9676,-54.0152 652.8452,-60.3964\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f456b2de860>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(treedot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtudes de los arboles de decision:\n",
    "\n",
    "- Metodo poderoso y probado\n",
    "- Interpretable\n",
    "- No necesita escalar los datos (clasificación), y menos preprocesamiento de variables\n",
    "\n",
    "Sin embargo en la practica existen modelos que obtienen mejor rendimiento. Como mejorar el modelo de arboles de decisión?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concepto General**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest y Gradient Boosted Trees, forman parte de una familia de algoritmos que se denominan ensembles.\n",
    "\n",
    "$$ Ensemble = Submodelos \\rightarrow Entrenamiento \\rightarrow Predicciones_{Intermedias} \\rightarrow Voto \\rightarrow Prediccion_{final}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cómo funciona el algoritmo Random Forest?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar cientos de modelos de arboles de decisión que serán entrenados sobre **conjuntos de datos bootstrapeados** del conjunto de datos original y donde para cada etapa de separación el **conjunto de features elegibles** sera un subconjunto aleatorio del conjunto original de features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/rf_tree.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada uno de los arboles entrenados luego podrá votar por su predicción y promediaremos estos votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/random_forest.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensembles del pobre (\"Poor man's ensembles\")**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrenar diversos modelos a mano\n",
    "- Promediar el resultado\n",
    "- Owen Zhang, número 1 de Kaggle.com durante un largo tiempo, ocupaba esta estrategia promediando diversos modelos XGBoost.\n",
    "- ``from sklearn.ensemble import VotingClassifier`` sirve por ejemplo para hacer un ensemble manual de clasificación\n",
    "\n",
    "En general los ensembles del pobre funcionan ya que cada uno de los modelos que votarán en conjunto son bastante fuertes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Porqué RF es poderoso?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  **Leo Breiman** creador del Random Forest demostró que un ensemble podía tener buen poder de generalización sí:\n",
    "  <ol>\n",
    "    <li>Los submodelos tienen buen poder de predicción</li>\n",
    "    <li>Los submodelos están descorrelacionados</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así el algoritmo de Random Forest compromete un poco de poder de predicción de cada uno de los decision trees que arma, pero la forma aleatoria de generarlos hace que esten **fuertemente descorrelacionados**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "forest = RandomForestRegressor(200)\n",
    "results = cross_validate(forest,X,y,cv=5,scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9653331511572368\n",
      "0.5334053076084458\n"
     ]
    }
   ],
   "source": [
    "test_scores = results['test_score']\n",
    "train_scores = results['train_score']\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor resultado que Lasso! Ya no tenemos Bias y tenemos un mejor score r2. Sin embargo tenemos una diferencia importante entre score de entrenamiento y de test (overfit).\n",
    "\n",
    "El R Cuadrado se define como la proporción de la varianza total de la variable explicada por la regresión. El R Cuadrado, también llamado coeficiente de determinación, refleja la bondad del ajuste de un modelo a la variable que pretender explicar. http://economipedia.com/definiciones/r-cuadrado-coeficiente-determinacion.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "ensemble = GradientBoostingRegressor()\n",
    "results = cross_validate(ensemble,X,y,cv=5,scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9151328807138182\n",
      "0.5402534704749634\n"
     ]
    }
   ],
   "source": [
    "test_scores = results['test_score']\n",
    "train_scores = results['train_score']\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo optimizamos los parametros de este último modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fijar un learning rate alto\n",
    "- Fijar parametros de los arboles\n",
    "- Fijados estos parametros, elegir el mejor numero de estimadores que conforman el ensemble\n",
    "- (Tarea) Con el learning rate dado y el numero de estimadores óptimo, optimizar los parametros de los arboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ahora dijimos que:\n",
    "    \n",
    "- train_test_split servia para evaluaciones rapidas, testeos y prototipaje\n",
    "- cross_validate es un método más robusto para poder estimar el rendimiento de tu algoritmo\n",
    "\n",
    "Sin embargo una vez que hemos finalizado nuestra etapa de prototipaje y ya queremos establecer un modelo definitivo deberiamos seguir el flujo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/grid_search_crossval.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_test1 = {'n_estimators': range(20,501,20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20,\n",
       " 40,\n",
       " 60,\n",
       " 80,\n",
       " 100,\n",
       " 120,\n",
       " 140,\n",
       " 160,\n",
       " 180,\n",
       " 200,\n",
       " 220,\n",
       " 240,\n",
       " 260,\n",
       " 280,\n",
       " 300,\n",
       " 320,\n",
       " 340,\n",
       " 360,\n",
       " 380,\n",
       " 400,\n",
       " 420,\n",
       " 440,\n",
       " 460,\n",
       " 480,\n",
       " 500]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(param_test1['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                     min_samples_split=500,\n",
    "                                     min_samples_leaf=50,\n",
    "                                     max_depth=8,\n",
    "                                     max_features='sqrt',\n",
    "                                     subsample=0.8,\n",
    "                                     random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gsearch1 = GridSearchCV(estimator,\n",
    "                       param_grid = param_test1, #En este caso movemos solo una variable, pero puedens ser más\n",
    "                       scoring='r2',\n",
    "                       cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=8,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=50, min_samples_split=500,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=10, subsample=0.8, verbose=0,\n",
       "             warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': range(20, 501, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbeltranleon/.virtualenvs/mlenv/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.65598, std: 0.05742, params: {'n_estimators': 20},\n",
       "  mean: 0.72070, std: 0.06234, params: {'n_estimators': 40},\n",
       "  mean: 0.73562, std: 0.06369, params: {'n_estimators': 60},\n",
       "  mean: 0.73940, std: 0.06219, params: {'n_estimators': 80},\n",
       "  mean: 0.74264, std: 0.06169, params: {'n_estimators': 100},\n",
       "  mean: 0.74603, std: 0.06214, params: {'n_estimators': 120},\n",
       "  mean: 0.74918, std: 0.06230, params: {'n_estimators': 140},\n",
       "  mean: 0.75038, std: 0.06204, params: {'n_estimators': 160},\n",
       "  mean: 0.75206, std: 0.06192, params: {'n_estimators': 180},\n",
       "  mean: 0.75302, std: 0.06353, params: {'n_estimators': 200},\n",
       "  mean: 0.75395, std: 0.06290, params: {'n_estimators': 220},\n",
       "  mean: 0.75388, std: 0.06399, params: {'n_estimators': 240},\n",
       "  mean: 0.75399, std: 0.06438, params: {'n_estimators': 260},\n",
       "  mean: 0.75359, std: 0.06339, params: {'n_estimators': 280},\n",
       "  mean: 0.75444, std: 0.06443, params: {'n_estimators': 300},\n",
       "  mean: 0.75323, std: 0.06478, params: {'n_estimators': 320},\n",
       "  mean: 0.75303, std: 0.06389, params: {'n_estimators': 340},\n",
       "  mean: 0.75285, std: 0.06502, params: {'n_estimators': 360},\n",
       "  mean: 0.75169, std: 0.06396, params: {'n_estimators': 380},\n",
       "  mean: 0.75148, std: 0.06329, params: {'n_estimators': 400},\n",
       "  mean: 0.75068, std: 0.06295, params: {'n_estimators': 420},\n",
       "  mean: 0.75067, std: 0.06336, params: {'n_estimators': 440},\n",
       "  mean: 0.75040, std: 0.06240, params: {'n_estimators': 460},\n",
       "  mean: 0.74978, std: 0.06202, params: {'n_estimators': 480},\n",
       "  mean: 0.74947, std: 0.06209, params: {'n_estimators': 500}],\n",
       " {'n_estimators': 300},\n",
       " 0.7544409799641042)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = cross_validate(gsearch1.best_estimator_,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8299010496758678\n",
      "0.7416023657878003\n"
     ]
    }
   ],
   "source": [
    "test_scores = final_results['test_score']\n",
    "train_scores = final_results['train_score']\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=8,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=50, min_samples_split=500,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "             presort='auto', random_state=10, subsample=0.8, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usamos 300 que fue el valor que nos dió el gsearch {'n_estimators': 300},\n",
    "\"\"\"estimator = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                     min_samples_split=500,\n",
    "                                     min_samples_leaf=50,\n",
    "                                     max_depth=8,\n",
    "                                     max_features='sqrt',\n",
    "                                     subsample=0.8,\n",
    "                                     random_state=10,\n",
    "                                     n_estimators=300)\"\"\"\n",
    "\n",
    "estimator = gsearch1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=8,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=50, min_samples_split=500,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "             presort='auto', random_state=10, subsample=0.8, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8097780523501505"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflexiones de cierre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recursos **\n",
    "\n",
    "- Reddit /machinelearning y /learnmachinelearning\n",
    "- Analytics Vidhya y KD Nuggets\n",
    "- Kaggle.com y \"There is no Free Hunch\" Blog\n",
    "- Arxiv, papers\n",
    "- Libros: \"Pattern Recognition and Machine Learning\" C.Bishop y \"Elements of Statistical Learning\".\n",
    "\n",
    "** Próximos pasos **\n",
    "\n",
    "- Matemáticas\n",
    "- Praxis: Feature Engineering, Model Selection y Tuning\n",
    "- Deep Learning para NLP y Computer Vision\n",
    "- Machine Learning Bayesiano"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
